import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sqlalchemy import create_engine, text
import pickle
import os
from datetime import datetime
from gensim.models import Word2Vec, FastText
from transformers import AutoTokenizer, AutoModel
from TurkishStemmer import TurkishStemmer
import torch
from nltk.tokenize import word_tokenize
import nltk
import re
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

class NLPTrainer:
    def __init__(self):
        self.engine = None
        self.df = None
        self.vectorizer = None
        self.model_path = "models"
        self.categories = ['donanim', 'yazilim', 'ag']
        self.word2vec_model = None
        self.fasttext_model = None
        self.bert_model = None
        self.bert_tokenizer = None
        self.stemmer = TurkishStemmer()
        
        try:
            nltk.download('punkt', quiet=True, raise_on_error=True)
            nltk.download('punkt_tab', quiet=True, raise_on_error=True)
            
            # BERT modelini yÃ¼kle
            self.bert_tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
            self.bert_model = AutoModel.from_pretrained("dbmdz/bert-base-turkish-cased")
        except Exception as e:
            print(f"Model yÃ¼kleme hatasÄ±: {str(e)}")

    def connect_database(self):
        """VeritabanÄ± baÄŸlantÄ±sÄ± kur"""
        try:
            connection_string = "mssql+pyodbc://usesen:usesen@DESKTOP-6QR83E3\\UGURMSSQL/FSM_Tickets?driver=SQL+Server"
            self.engine = create_engine(connection_string)
            print("âœ… VeritabanÄ± baÄŸlantÄ±sÄ± kuruldu")
        except Exception as e:
            print(f"âŒ VeritabanÄ± baÄŸlantÄ± hatasÄ±: {str(e)}")
            
    def load_data(self):
        """VeritabanÄ±ndan eÄŸitim verilerini ve eÅŸ anlamlÄ± kelimeleri yÃ¼kle"""
        try:
            with self.engine.connect() as conn:
                # EÅŸ anlamlÄ± kelimeleri Ã§ek
                synonyms_query = text("""
                    SELECT 
                        Kelime,
                        Es_Anlamli_Kelimeler as Esanlamlisi
                    FROM dbo.Kelime_Esanlamlilari
                """)
                
                self._load_tickets_data(conn)
                self._load_synonyms_data(conn, synonyms_query)
            
            self._analyze_data()
                
        except Exception as e:
            print(f"âŒ Veri yÃ¼kleme hatasÄ±: {str(e)}")
            self.synonyms_dict = {}

    def _load_tickets_data(self, conn):
        """Load tickets data from database"""
        tickets_query = text("""
            SELECT 
                Problem_Aciklamasi,
                Cozum_Aciklamasi,
                Kategori,
                Teknisyen
            FROM Tickets
        """)
        self.df = pd.read_sql(tickets_query, conn)
        print(f"âœ… {len(self.df)} adet ticket yÃ¼klendi")
        
    def _load_synonyms_data(self, conn, query):
        """Load synonyms data from database"""
        self.synonyms_df = pd.read_sql(query, conn)
        print(f"âœ… {len(self.synonyms_df)} adet eÅŸ anlamlÄ± kelime yÃ¼klendi")
        
        # EÅŸ anlamlÄ± kelimeleri sÃ¶zlÃ¼ÄŸe Ã§evir
        self.synonyms_dict = {}
        for _, row in self.synonyms_df.iterrows():
            self.synonyms_dict[row['Kelime']] = row['Esanlamlisi']
        
    def _analyze_data(self):
        """Veri setini analiz et"""
        print("\nğŸ“Š Veri Analizi:")
        print(f"Toplam Ticket: {len(self.df)}")
        print("\nKategori DaÄŸÄ±lÄ±mÄ±:")
        print(self.df['Kategori'].value_counts())
        print("\nTeknisyen DaÄŸÄ±lÄ±mÄ±:")
        print(self.df['Teknisyen'].value_counts().head())
        
    def preprocess_text(self, text):
        """Metin Ã¶n iÅŸleme"""
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # Noktalama iÅŸaretlerini kaldÄ±r
        text = re.sub(r'[^\w\s]', '', text)
        
        # Stemming uygula
        words = text.split()
        stemmed_words = [self.stemmer.stem(word) for word in words]
        
        return ' '.join(stemmed_words)

    def generate_synonyms(self):
        """Problem aÃ§Ä±klamalarÄ±ndan eÅŸ anlamlÄ± kelimeleri Ã¶ÄŸren ve kaydet"""
        try:
            print("\nğŸ” EÅŸ anlamlÄ± kelimeler Ã¶ÄŸreniliyor...")
            
            # Metinleri temizle ve tokenize et
            sentences = []
            
            print("Metin Ã¶n iÅŸleme yapÄ±lÄ±yor...")
            for text in tqdm(self.df['Problem_Aciklamasi'].fillna('')):
                # Her cÃ¼mleyi kelimelere ayÄ±r
                if words := word_tokenize(self.preprocess_text(text)):
                    sentences.append(words)

            if not sentences:
                print("âŒ Ä°ÅŸlenecek cÃ¼mle bulunamadÄ±")
                return

            print(f"âœ… {len(sentences)} cÃ¼mle iÅŸlendi")
            print(f"Ã–rnek cÃ¼mle: {sentences[0]}")

            # Word2Vec modelini eÄŸit
            print("\nWord2Vec modeli eÄŸitiliyor...")
            self.word2vec_model = Word2Vec(
                sentences=sentences,
                vector_size=100,
                window=5,
                min_count=2,  # En az 2 kez geÃ§en kelimeler
                workers=4,
                epochs=10  # Epoch sayÄ±sÄ±nÄ± artÄ±r
            )
            
            # FastText modelini eÄŸit
            print("\nFastText modeli eÄŸitiliyor...")
            self.fasttext_model = FastText(
                sentences=sentences,
                vector_size=100,
                window=5,
                min_count=2,
                workers=4,
                epochs=10
            )

            # Her kategori iÃ§in iÅŸlem yap
            for kategori in self.categories:
                print(f"\n{kategori.upper()} kategorisi iÅŸleniyor...")
                kategori_texts = self.df[self.df['Kategori'].str.lower() == kategori]['Problem_Aciklamasi']
                
                # Preprocess and filter empty texts
                processed_texts = [self.preprocess_text(text) for text in kategori_texts if text and isinstance(text, str)]
                
                if not processed_texts:
                    print(f"âš ï¸ {kategori} kategorisinde iÅŸlenecek metin bulunamadÄ±")
                    continue
                
                # TF-IDF with non-empty texts
                vectorizer = TfidfVectorizer(max_features=100, min_df=2)  # Add min_df parameter
                tfidf_matrix = vectorizer.fit_transform(processed_texts)
                feature_names = vectorizer.get_feature_names_out()
                
                # Her kelime iÃ§in benzer kelimeleri bul
                for word in tqdm(feature_names, desc="Kelimeler iÅŸleniyor"):
                    if synonyms := self._find_word_synonyms(word, kategori):
                        self._save_synonym(word, ','.join(synonyms), kategori)
                        print(f"âœ… {word} -> {synonyms}")

            print("\nâœ… EÅŸ anlamlÄ± kelimeler Ã¶ÄŸrenildi ve kaydedildi")
            
        except Exception as e:
            print(f"âŒ EÅŸ anlamlÄ± kelime Ã¶ÄŸrenme hatasÄ±: {str(e)}")
            raise  # HatanÄ±n detayÄ±nÄ± gÃ¶rmek iÃ§in

    def _get_bert_embeddings(self, texts):
        """BERT embeddings hesapla"""
        embeddings = []
        
        with torch.no_grad():
            for text in tqdm(texts, desc="BERT embeddings hesaplanÄ±yor"):
                inputs = self.bert_tokenizer(text, return_tensors="pt", padding=True, truncation=True)
                outputs = self.bert_model(**inputs)
                embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())
        
        return np.array(embeddings)

    def _find_word_synonyms(self, word, category):
        """Bir kelime iÃ§in tÃ¼m modelleri kullanarak eÅŸ anlamlÄ±larÄ± bul"""
        synonyms = set()
        
        # Debug iÃ§in print ekleyelim
        print(f"Aranan kelime: {word}")
        
        # Word2Vec benzerliÄŸi
        try:
            similar_words = self.word2vec_model.wv.most_similar(word, topn=3)
            print(f"Word2Vec benzer kelimeler: {similar_words}")
            synonyms.update([w for w, s in similar_words if s > 0.6])
        except Exception as e:
            print(f"Word2Vec hatasÄ±: {str(e)}")
        
        # FastText benzerliÄŸi
        try:
            similar_words = self.fasttext_model.wv.most_similar(word, topn=3)
            print(f"FastText benzer kelimeler: {similar_words}")
            synonyms.update([w for w, s in similar_words if s > 0.6])
        except Exception as e:
            print(f"FastText hatasÄ±: {str(e)}")
        
        print(f"Bulunan eÅŸ anlamlÄ±lar: {list(synonyms)}\n")
        return list(synonyms)

    def preprocess_data(self):
        """Verileri Ã¶n iÅŸleme"""
        try:
            print("\nğŸ”„ Veri Ã¶n iÅŸleme baÅŸladÄ±...")
            
            # Eksik deÄŸerleri temizle
            self.df = self.df.dropna(subset=['Problem_Aciklamasi', 'Cozum_Aciklamasi'])
            
            print("Metinler iÅŸleniyor...")
            # Metinleri iÅŸle
            tqdm.pandas()
            self.df['processed_problem'] = self.df['Problem_Aciklamasi'].progress_apply(self.preprocess_text)
            self.df['processed_solution'] = self.df['Cozum_Aciklamasi'].progress_apply(self.preprocess_text)
            
            # EÅŸ anlamlÄ± kelime deÄŸiÅŸimi - daha verimli hale getirildi
            print("EÅŸ anlamlÄ± kelimeler uygulanÄ±yor...")
            def apply_synonyms(row):
                text = row['processed_problem']
                category = row['Kategori'].lower()
                words = text.split()
                
                for word in words:
                    if similar := self._find_word_synonyms(word, category):
                        text = text.replace(word, similar[0])
                return text
            
            self.df['processed_problem'] = self.df.progress_apply(apply_synonyms, axis=1)
            
            print("âœ… Veri Ã¶n iÅŸleme tamamlandÄ±")
            
        except Exception as e:
            print(f"âŒ Veri Ã¶n iÅŸleme hatasÄ±: {str(e)}")

    def train_model(self):
        """TF-IDF modelini eÄŸit"""
        try:
            if self.df is None or len(self.df) == 0:
                print("âŒ EÄŸitim iÃ§in veri bulunamadÄ±")
                return

            print("\nğŸ¤– Model eÄŸitimi baÅŸladÄ±...")
            
            # TF-IDF Vectorizer
            self.vectorizer = TfidfVectorizer(
                max_features=5000,
                ngram_range=(1, 2),
                stop_words=['ve', 'veya', 'ile', 'iÃ§in']
            )
            
            # Modeli eÄŸit
            X = self.vectorizer.fit_transform(self.df['processed_problem'])
            
            print(f"âœ… Model eÄŸitildi: {X.shape[0]} Ã¶rnek, {X.shape[1]} Ã¶zellik")
            
            # Modeli kaydet
            self._save_model()
            
        except Exception as e:
            print(f"âŒ Model eÄŸitim hatasÄ±: {str(e)}")
            
    def _save_model(self):
        """EÄŸitilen modeli kaydet"""
        try:
            if not os.path.exists(self.model_path):
                os.makedirs(self.model_path)
                
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Vectorizer'Ä± kaydet
            vectorizer_path = f"{self.model_path}/vectorizer_{timestamp}.pkl"
            with open(vectorizer_path, 'wb') as f:
                pickle.dump(self.vectorizer, f)
                
            # EÄŸitim verilerini kaydet
            data_path = f"{self.model_path}/training_data_{timestamp}.pkl"
            with open(data_path, 'wb') as f:
                pickle.dump({
                    'problems': self.df['processed_problem'].tolist(),
                    'solutions': self.df['processed_solution'].tolist(),
                    'categories': self.df['Kategori'].tolist()
                }, f)
                
            print(f"âœ… Model kaydedildi: {vectorizer_path}")
            
        except Exception as e:
            print(f"âŒ Model kaydetme hatasÄ±: {str(e)}")
            
    def test_model(self, test_problems):
        """Modeli test et"""
        if not (self.vectorizer and hasattr(self.vectorizer, 'vocabulary_')):
            print("âŒ Model henÃ¼z eÄŸitilmemiÅŸ")
            return

        print("\nğŸ§ª Model testi baÅŸladÄ±...")
        
        for problem in test_problems:
            print(f"\nğŸ“ Test Problemi: {problem}")
            
            # Problemi vektÃ¶rize et
            problem_vec = self.vectorizer.transform([problem.lower()])
            
            # Benzerlik hesapla
            similarities = (problem_vec * self.vectorizer.transform(
                self.df['processed_problem']
            ).T).toarray()[0]
            
            # En benzer 3 Ã§Ã¶zÃ¼mÃ¼ bul
            most_similar = similarities.argsort()[-3:][::-1]
            
            print("\nğŸ’¡ Benzer Ã‡Ã¶zÃ¼mler:")
            for idx in most_similar:
                print(f"- {self.df.iloc[idx]['Cozum_Aciklamasi']}")
                print(f"  Benzerlik: {similarities[idx]:.2%}")
                print(f"  Kategori: {self.df.iloc[idx]['Kategori']}")
                print()

    def _truncate_synonyms_table(self):
        """Truncate the synonyms table"""
        with self.engine.connect() as conn:
            truncate_query = text("TRUNCATE TABLE dbo.Kelime_Esanlamlilari")
            conn.execute(truncate_query)
            conn.commit()
            print("âœ… Kelime_Esanlamlilari tablosu temizlendi")

    def _save_synonym(self, kelime, esanlamlisi, kategori):
        """EÅŸ anlamlÄ± kelimeyi veritabanÄ±na kaydet"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    INSERT INTO dbo.Kelime_Esanlamlilari 
                    (Kelime, Es_Anlamli_Kelimeler, Kategori, Kullanim_Frekansi, Son_Kullanim)
                    VALUES (:kelime, :esanlamlisi, :kategori, 1, GETDATE())
                """)
                conn.execute(query, {
                    'kelime': kelime,
                    'esanlamlisi': esanlamlisi,
                    'kategori': kategori
                })
                conn.commit()
        except Exception as e:
            print(f"âŒ Kelime kaydetme hatasÄ±: {str(e)}")

    def find_similar_words(self, word, category=None):
        """Bir kelime iÃ§in eÅŸ anlamlÄ±larÄ± bul"""
        try:
            similar_words = []
            
            # Word2Vec benzerliÄŸi
            if self.word2vec_model and word in self.word2vec_model.wv:
                similar_words = [w for w, s in self.word2vec_model.wv.most_similar(word, topn=3) if s > 0.6]
            
            # Kategori bazlÄ± filtreleme
            if category:
                with self.engine.connect() as conn:
                    query = text("""
                        SELECT Es_Anlamli_Kelimeler
                        FROM dbo.Kelime_Esanlamlilari
                        WHERE Kategori = :kategori AND Kelime = :kelime
                    """)
                    result = conn.execute(query, {'kategori': category, 'kelime': word}).fetchone()
                    if result and result[0]:
                        similar_words.extend(result[0].split(','))
            
            return list(set(similar_words))  # TekrarlarÄ± kaldÄ±r
            
        except Exception as e:
            print(f"âŒ Benzer kelime bulma hatasÄ±: {str(e)}")
            return []

def main():
    trainer = NLPTrainer()
    
    # VeritabanÄ± baÄŸlantÄ±sÄ±
    trainer.connect_database()
    
    # Veri yÃ¼kleme
    trainer.load_data()
    
    # EÅŸ anlamlÄ±larÄ± Ã¶ÄŸren (Ã¶nce modelleri eÄŸit)
    print("\n1. EÅŸ anlamlÄ± kelimeler Ã¶ÄŸreniliyor...")
    trainer._truncate_synonyms_table()
    trainer.generate_synonyms()
    
    # Veri Ã¶n iÅŸleme ve model eÄŸitimi
    print("\n2. Veri Ã¶n iÅŸleme yapÄ±lÄ±yor...")
    trainer.preprocess_data()
    
    print("\n3. Model eÄŸitiliyor...")
    trainer.train_model()
    
    # Test
    test_problems = [
        "Outlook aÃ§Ä±lmÄ±yor ve e-posta gÃ¶nderemiyor",
        "SAP sistemine giriÅŸ yapÄ±lamÄ±yor, ekran donuyor",
        "VPN baÄŸlantÄ±sÄ± sÃ¼rekli kopuyor",
        "Ä°nternet Ã§ok yavaÅŸ, sayfalara giremiyorum"
    ]
    
    trainer.test_model(test_problems)

if __name__ == "__main__":
    main() 